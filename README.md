### Hi there ğŸ‘‹, I'm Yang Jianxin
[![yangjianxin1's GitHub stats](https://github-readme-stats-git-masterorgs-github-readme-stats-team.vercel.app/api?username=yangjianxin1&hide=prs)](https://github.com/anuraghazra/github-readme-stats)

I'm a NLPer interested in Large Language Model and graduated from [SYSU](https://www.sysu.edu.cn/) with a master's degree.

In my free time, I like to write technical blogs on [[Wechat Official Accounts: YeungNLP]]() and [[Zhihu: çº¢é›¨ç“¢æ³¼]](https://www.zhihu.com/people/jian-xin-15-96)

ğŸ”­ Experiences:
- **Shopee**, responsible for building NLP algorithm ability about Customer Service. (from 2022-04 to now)
- **Tencent**, responsible for building NLP algorithm ability about Product Understanding. (from 2021-06 to 2022-04)
- **Alibaba**, Internship at Alibaba  (from 2020-06 to 2020-09).

âš™ Here are some my public projects:

| Project                                                                           | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | Code                                                                                      |
|-----------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|
| [Firefly](https://github.com/yangjianxin1/Firefly)                                | One-stop training for LLMs. Some achievements:<br> 1. [firefly-llama2-13b](https://huggingface.co/YeungNLP/firefly-llama2-13b) ranked **3rd** among all 13B models on [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard), only 0.5 points less than 1st.  <br> 2. [firefly-llama-30b](https://huggingface.co/YeungNLP/firefly-llama-30b) ranked **10th** among all 30B models on [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) trained with single V100. <br> 3. [firefly-baichuan-13b](https://huggingface.co/YeungNLP/firefly-baichuan-13b) achieves over **1.63 million downloads**. <br> 4. [firefly-qwen1.5-en-7b-dpo](https://huggingface.co/YeungNLP/firefly-qwen1.5-en-7b-dpo-v0.1) improves 7.21 points compared with the official chat model. <br> 5. [firefly-gemma-7b](https://huggingface.co/YeungNLP/firefly-gemma-7b) improves 9.37 points compared with the official chat model.| ![](https://img.shields.io/github/stars/yangjianxin1/Firefly?style=social)                  |
| [GPT2-chitchat](https://github.com/yangjianxin1/GPT2-chitchat)                    | Chinese GPT2 for chitchat                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | ![](https://img.shields.io/github/stars/yangjianxin1/GPT2-chitchat?style=social)          |
| [Firefly-LLaMA2-Chinese](https://github.com/yangjianxin1/Firefly-LLaMA2-Chinese)  | Chinese Llama2 with efficient and effective training method.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | ![](https://img.shields.io/github/stars/yangjianxin1/Firefly-LLaMA2-Chinese?style=social) |
| [LongQLoRA](https://github.com/yangjianxin1/LongQLoRA)                            | Efficient and Effective method for extending context length of Llama2 to 8192 with single V100.   [Technical Report](https://arxiv.org/abs/2311.04879)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | ![](https://img.shields.io/github/stars/yangjianxin1/LongQLoRA?style=social)              |
| [CPM](https://github.com/yangjianxin1/CPM)                                        | Chinese composition model based on CPM                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | ![](https://img.shields.io/github/stars/yangjianxin1/CPM?style=social)                    |
| [CLIP-Chinese](https://github.com/yangjianxin1/CLIP-Chinese)                      | Chinese CLIP model trained with 1.4 million image-text pairs                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | ![](https://img.shields.io/github/stars/yangjianxin1/CLIP-Chinese?style=social)           |
| [ClipCap-Chinese](https://github.com/yangjianxin1/ClipCap-Chinese)                | Chinese image caption model based on clip and mengzi                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | ![](https://img.shields.io/github/stars/yangjianxin1/Clipcap-Chinese?style=social)        |
| [OFA-Chinese](https://github.com/yangjianxin1/OFA-Chinese)                        | Chinese multi-modal unified pre-training model                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | ![](https://img.shields.io/github/stars/yangjianxin1/OFA-Chinese?style=social)            |
| [LLMPruner](https://github.com/yangjianxin1/LLMPruner)                            | Prune vocabulary of LLMs to save memory in training.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | ![](https://img.shields.io/github/stars/yangjianxin1/LLMPruner?style=social)              |


ğŸ“ Here are some my technical blogs:
- ğŸ“ [ä½¿ç”¨Fireflyåœ¨å•å¡V100ä¸Šå¯¹Qwen1.5è¿›è¡ŒSFTå’ŒDPOï¼Œå¤§å¹…è¶…è¶ŠQwen1.5å’ŒGemma](https://mp.weixin.qq.com/s/fTaGzuIZq3Uig0524GiGPA)
- ğŸ“ [å›¾è§£å¤§æ¨¡å‹æ¨ç†ä¼˜åŒ–ä¹‹KV Cache](https://mp.weixin.qq.com/s/7Fm8LbUN9jQ2HqxPbUU7UQ)
- ğŸ“ [Mixtral-8x7B MoEå¤§æ¨¡å‹å¾®è°ƒå®è·µï¼Œè¶…è¶ŠLlama2-65B](https://mp.weixin.qq.com/s/f24e-Tp-1WyXTbVOzePvhg)
- ğŸ“ [LongQLoRAï¼šå•å¡é«˜æ•ˆæ‰©å±•LLaMA2-13Bçš„ä¸Šä¸‹æ–‡é•¿åº¦](https://mp.weixin.qq.com/s/lptWXi9sZXd2MTTXZsDiPw)
- ğŸ“ [è¯¦è§£åŸºäºè°ƒæ•´RoPEæ—‹è½¬è§’åº¦çš„å¤§æ¨¡å‹é•¿åº¦å¤–æ¨æ–¹æ³•](https://mp.weixin.qq.com/s/RtI95hu-ZLxGkdGuNIkERQ)
- ğŸ“ [å›¾è§£RoPEæ—‹è½¬ä½ç½®ç¼–ç åŠå…¶ç‰¹æ€§](https://mp.weixin.qq.com/s/-1xVXjoM0imXMC7DKqo-Gw)
- ğŸ“ [QLoRAè½»é‡çº§å¢é‡é¢„è®­ç»ƒæ–¹æ¡ˆï¼ŒåŠæ±‰åŒ–Llama2çš„å®è·µ](https://mp.weixin.qq.com/s/26-Qxma9M2wGoTQgOlKRmQ)
- ğŸ“ [æºç è§£æChatGLM2å¤šè½®å¯¹è¯è®­ç»ƒæ–¹æ³•çš„ä¸è¶³ï¼Œä»¥åŠæ”¹è¿›æ–¹æ³•](https://mp.weixin.qq.com/s/nhogoWnzl3nrs_77r38_UA)
- ğŸ“ [å¾®è°ƒç™¾å·Baichuan-13Bä¿å§†å¼æ•™ç¨‹ï¼Œæ‰‹æŠŠæ‰‹æ•™ä½ è®­ç»ƒç™¾äº¿å¤§æ¨¡å‹](https://mp.weixin.qq.com/s/ZBY6kbogHjbCQvZBzNEqag)
- ğŸ“ [QLoRAæ–‡ç« è§£è¯» & å•å¡é«˜æ•ˆå¾®è°ƒbloom-7b1](https://mp.weixin.qq.com/s/DED7yeiE0DibsVzTmMeDOw)
- ğŸ“ [Firefly(æµè¤): ä¸­æ–‡å¯¹è¯å¼å¤§è¯­è¨€æ¨¡å‹](https://mp.weixin.qq.com/s/TX7wj8IzD_EaMTvk0bjRtA)
- ğŸ“ [LLMPrunerï¼šå¤§è¯­è¨€æ¨¡å‹è£å‰ªå·¥å…·](https://mp.weixin.qq.com/s/leVtrwZc1zLput51Nr99lw)


